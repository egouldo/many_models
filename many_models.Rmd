---
title: "Fitting many models with purrr, broom, dplyr"
output: html_notebook
---

Lets start simple, lets highlight some basic tools that we will need later, chiefly tools from the broom package.

# A tidy workflow for working with one model

Broom formatting tidy model summaries, tidies statistical models into tidy data-frames.
```{r load-broom}
library(broom) # For tidying fittted model output into tidy datafraems
```


## What are tidy dataframes / tidy data?

## Whats in a model? Sweeping up with broom

- tidy: component level statistics: coefficients, p-values, etc. ONE PER VARIABLE
- augment: observation level -fitted values, residuals. ONE PER OBSERVATION.
- glance - model level - R2, F-stat, deviance. ONE PER MODEL.

Each row is:

- tidy - a coefficient - nesting required
- augment - an observation from the original data, adds new cols to the original data, such as fitted values - nesting required
- glance- one row per model - nesting required

## Why would we want tidy model summaries?

- can easily visualise, such as with ggplot: fitted model in dataspace, coefficient plot, survival curves, lasso regression, etc.
- Working with MANY models: tidy models can be combined, and compared.

# Why do we look at multiple models?

- 'insight into the data and the relative merits of different models' removing the blindfold paper
- 'explore the process of fitting' - removing the blindfold paper
- explorign different parameters, methods, bootstrapping replicates, subgroup models, ensemble voting (andrew robinson slides)

Example instances, from:


1. Exploring the space of all possible models: E.g. for a given family, can explore different forms, like for a linear model we could generate all models with main efects. 
2. Varying model setting. Systematically alter the tuning parameters to observe the result. 
3. Fitting the same model to different datasets. cross-validation, bootstrapping, simulating, sensitivity analyses, etc.
4. Finding global optima - e.g. when model fitting might not converge to global optimum, you can have a collection of models generated from multiple random starts.

But difficult to visualise simultaneously. So we need to explore smaller sets of interesting models. We can narrow this down by first calculating descriptive statistics at multiple levels.

So this means that we often want to perform the same operation of different sets of data. How do we easily store, and access this data repetitively. Could program in for-loops, and write modelling functions. But there are a suite of tools out there that get the job done more efficiently (both in terms of computationally, and in terms of the actual code that you write).

# What packages are we working with and what do they do?

```{r load-libs}
library(glm2) # fit models, glms
library(dplyr) # data manipulation
library(tidyr) # For reshaping dataframes, specifically nesting
library(purrr) # For applying functions to nested dataframes
library(ggplot2) # good lookin plots, duh
```

I see two main workflows: 
1. when you have a single model that you want to repetitively fit to different pieces of the data.
2. when you have a selection of different models.

## A workflow for same model, many pieces:

What do we need?

1. dplyr: create new columns
2. tidyr: nested data with list columns
3. purrr: map functions, map nested dataframes to the modeling function or to broom function

### List-columns

Regular dataframes are essentially a collection of lists. So why cant we have a list of dataframes, say? Well we can 
using list-columns. `tidyr::nest()` nests dataframes into a single 'value' in the dataframe, which is essentially equivalent to a single element at the top-level of the list.

# References:

Robinson, D. (2014). broom: An R Package for Converting Statistical Analysis Objects Into Tidy Data Frames. [https://arxiv.org/pdf/1412.3565v2.pdf](https://arxiv.org/pdf/1412.3565v2.pdf)

Robinson, D., (2015) broom: An R Package to Convert Statistical Models into Tidy Data Frames, Paper presented at UP-STAT2015: Statistical Modelling in the Era of Data Science, SUNY, 4th November 2015, [http://varianceexplained.org/files/broom_presentation.pdf](http://varianceexplained.org/files/broom_presentation.pdf)

Wickham, H., Cook, D., Hofmann, H. (2015) Visualizing statistical models: removing the blindfold. Statistical Analysis and Data Mining: THe ASA Data Science Journal, 8(4), 203-235, doi: 10.1002/sam.11271

R For Data Science: Chapter 21 -- Iteration. [http://r4ds.had.co.nz/iteration.html#introduction-14](http://r4ds.had.co.nz/iteration.html#introduction-14)
